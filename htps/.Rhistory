sum(is.nan(A))
A[is.complex(A)]
get_A <- function(n, a, b, c, d){
library(pracma)
dt <- (d-c) / n
ds <- (b-a) / n
t <-  c + dt*((1:n - 0.5))
s <- a + ds*((1:n - 0.5))
mesh_grid <- meshgrid(t,s)
X  <- mesh_grid$X
Y  <- mesh_grid$Y
# A matrix
A <- dt*Y/(X%*%(X^2-Y^2)^1/2)
return(A)
}
# Run the function
n = 100
a = 0.1
b = 50
c = 0.11
d = 50
A <- get_A(n, a, b, c, d)
A
dim(A)
Y
dt
dt*Y
library(expm)
dt*Y/(X%*%(X^2-Y^2)%^%1/2)
get_A <- function(n, a, b, c, d){
library(pracma)
library(expm)
dt <- (d-c) / n
ds <- (b-a) / n
t <-  c + dt*((1:n - 0.5))
s <- a + ds*((1:n - 0.5))
mesh_grid <- meshgrid(t,s)
X  <- mesh_grid$X
Y  <- mesh_grid$Y
# A matrix
A <- dt*Y/(X%*%(X^2-Y^2)%^%1/2)
return(A)
}
n = 100
a = 0.1
b = 50
c = 0.11
d = 50
A <- get_A(n, a, b, c, d)
A
dim(A)
dt*Y/(X%*%(X%^%2-Y%^%2)%^%1/2)
X^2
X
X^2
X%^%2
dt*Y/(X%*%(X^2-Y^2)^0.5)
dt*((1:n - 0.5))
1:n
dt*((1:n) - 0.5)
dt*((1:n)) - 0.5)
dt*((1:n)) - 0.5)
dt*((1:n - 0.5))
dt*((1:n) - 0.5)
ds*((1:n) - 0.5)
(1:5)-0.5
browseVignettes(package = "univariateML")
# Sample from the A matrix, for example:
A <- matrix(rnorm(50),ncol=2)
A
# Sample from the A matrix, for example:
A <- matrix(rnorm(100), ncol=2)
A
## 75% of the sample size
smp_size <- floor(0.8 * nrow(A))
smp_size
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(A)), size = smp_size)
A[train_ind, ]
A[-train_ind, ]
# Sample from the A matrix, for example:
A <- matrix(rnorm(100), ncol=2)
A
## 80% of the sample size
smp_size <- floor(0.8 * nrow(A))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(A)), size = smp_size)
A_train <- A[train_ind, ]
A_test  <- A[-train_ind, ]
# Funcion para crear matriz A
get_A <- function(n, a, b, c, d){
library(tidyr)
library(pracma)
library(expm)
dt <- (d-c) / n
ds <- (b-a) / n
t <-  c + dt*((1:n) - 0.5)
s <- a + ds*((1:n) - 0.5)
mesh_grid <- meshgrid(t,s)
X  <- mesh_grid$X   # Matriz T
Y  <- mesh_grid$Y   # Matriz S
A <- matrix(numeric(n*n), nrow = n, ncol = n) # Matriz de 0
for(i in 1:n){
for(j in 1:n){
if(Y[i,j] > X[i,j]){
A[i,j] = 0
}
else{
A[i,j] <- chop(as.numeric(dt*Y[i, j] /(X[i,j]%*%(X[i,j]^2 - Y[i,j]^2)^(1/2))))
}
}
}
return(A)
}
# Correr la funcion para obtener la matriz A
n = 4
a = 0.1
b = 50
c = 0.11
d = 50
A <- get_A(n, a, b, c, d)
A
dim(A)
A
install.packages("stringr")                        # Install stringr package
str_remove(A, "^0+")
library(tidyr)
library(pracma)
library(expm)
library(stringr)
str_remove(A, "^0+")
str_remove(A, "^0")
# Funcion para crear matriz A
get_A <- function(n, a, b, c, d){
library(tidyr)
library(pracma)
library(expm)
dt <- (d-c) / n
ds <- (b-a) / n
t <-  c + dt*((1:n) - 0.5)
s <- a + ds*((1:n) - 0.5)
mesh_grid <- meshgrid(t,s)
X  <- mesh_grid$X   # Matriz T
Y  <- mesh_grid$Y   # Matriz S
A <- matrix(numeric(n*n), nrow = n, ncol = n) # Matriz de 0
for(i in 1:n){
for(j in 1:n){
if(Y[i,j] > X[i,j]){
A[i,j] = 0
}
else{
A[i,j] <- chop(as.numeric(dt*Y[i, j] /(X[i,j]%*%(X[i,j]^2 - Y[i,j]^2)^(1/2))))
}
}
}
return(A)
}
round(A)
# Funcion para crear matriz A
get_A <- function(n, a, b, c, d){
library(tidyr)
library(pracma)
library(expm)
dt <- (d-c) / n
ds <- (b-a) / n
t <-  c + dt*((1:n) - 0.5)
s <- a + ds*((1:n) - 0.5)
mesh_grid <- meshgrid(t,s)
X  <- mesh_grid$X   # Matriz T
Y  <- mesh_grid$Y   # Matriz S
A <- matrix(numeric(n*n), nrow = n, ncol = n) # Matriz de 0
for(i in 1:n){
for(j in 1:n){
if(Y[i,j] > X[i,j]){
A[i,j] = 0
}
else{
A[i,j] <- chop(as.numeric(dt*Y[i, j] /(X[i,j]%*%(X[i,j]^2 - Y[i,j]^2)^(1/2))))
}
}
}
return(A)
}
# Correr la funcion para obtener la matriz A
n = 4
a = 0.1
b = 50
c = 0.11
d = 50
A <- get_A(n, a, b, c, d)
A
dim(A)
round(A)
dim(A)
round(A, digits = 5)
install.packages("radix")
install.packages("distill")
install.packages("BiocManager")
library(distill)
install.packages("rticles")
########################################################################
# Thank you to an anonymous reviewer for INLA code  ####################
# adapted in this document                          ####################
########################################################################
library(RandomFields)
library(geoR)
library(fields)
library(prodlim)
# load INLA
library(INLA)
# sample size
n=100
beta=1.5
# marginal variance of the field
sigma.sq=1.5
# nugget variance
tau.sq=0.1
# smoothness parameter
nu=1
# scale (range)
phi=0.15
# mean parameter (constant mean trend)
mean=4
# define grid as 91 by 91 on the unit square
xseq=seq(0,1,length.out=91)
yseq=seq(0,1,length.out=91)
gridFull=expand.grid(xseq,yseq)
# define covariance model for the field S
model <- RMwhittle(nu=nu, var=sigma.sq, scale=phi)
# generate the raw data for S
set.seed(2)
rawDat <- RFsimulate(model, x=as.matrix(gridFull), exactness=TRUE)$variable1 + mean
# combine coordinates X with corresponding values for S
obj <- cbind(cbind(gridFull[,1], gridFull[,2]), rawDat)
cbind(cbind(gridFull[,1], gridFull[,2]), rawDat)
# combine coordinates X with corresponding values for S
obj <- cbind(cbind(gridFull[,1], gridFull[,2]), rawDat)
geodata <- as.geodata(obj, coords.col = 1:2, data.col = 3)
geodata
# sample the data  with intensity exp(beta*S(x))/int(exp(beta*S(u))du)
sampData <- sample.geodata(geodata, size = n, prob = exp(beta * geodata$data))
# add nugget variance to Y's
sampData$data <- sampData$data + rnorm(n, mean = 0, sd = sqrt(tau.sq))
# plot the data
image.plot(xseq,yseq,matrix(rawDat, nrow=length(xseq), ncol=length(yseq)),
xlab="Longitude", ylab="Latitude", col=rev(heat.colors(10)))
points(sampData$coords, pch=19, cex=.5)
# estimate parameters ignoring any preferential effects
standardMLE <- likfit(sampData, coords = sampData$coords,
data = sampData$data, kappa=nu, ini=c(0.5, 0.5))
# defined discretisation for INLA predictions/[X|S]
# defined discretisation for INLA predictions/[X|S]
m=31
Sseq <- seq(0,1,length.out=m)
# prediction grid (lattice)
predGrid <- expand.grid(Sseq,Sseq)
colnames(predGrid) <- c("V1", "V2")
# full grid (including sampling locations)
INLAgrid <- unique(rbind(predGrid, sampData$coords))
rep(NA, nrow(INLAgrid))
########################################################################
# Use INLA to estimate corrected parameters ############################
########################################################################
y.pref = rep(NA, nrow(INLAgrid))
# find sampling locations in full grid
pointer1 <- row.match(data.frame(sampData$coords), INLAgrid)
pointer1
pp.pref <- pointer1
pp.pref
y.pref[pp.pref]
y.pref[pp.pref] = sampData$data
y.pref
# Create INLA mesh
mesh <- inla.mesh.create(loc = as.matrix(INLAgrid),
extend = TRUE, refine = TRUE)
plot(mesh, asp=1)
# Locate the input locations in the output mesh
ii0 <- mesh$idx$loc
# Create INLA Matern SPDE model
spde <- inla.spde2.pcmatern(mesh = mesh, constr = FALSE,
prior.range = c(.15, 0.01),
prior.sigma = c(1.5, 0.01))
# Prepare the data sets for INLA
# Prepare the data sets for INLA
nGrid = nrow(INLAgrid)
ii <- c(ii0, rep(NA, nGrid))
jj <- c(rep(NA, nGrid), ii0)
alpha = c(rep(0,nGrid), rep(1,nGrid))
mu = c(rep(1,nGrid), rep(0,nGrid))
points.pref = rep(0,nGrid)
points.pref[pp.pref] = 1
# Preferential sampling
yy.pref = matrix(NA,2*nGrid,2)
yy.pref
yy.pref = matrix(NA,2*nGrid,2)
yy.pref[1:nGrid,1] = y.pref
yy.pref[nGrid+1:nGrid,2] = points.pref
data.pref.pref = list(yy=yy.pref,mu=mu,ii=ii,jj=jj,alpha=alpha)
# Create data for INLA fitting
data.pref.pref_spde <- list(yy = yy.pref, mu = mu, ii = ii, jj = jj, alpha = alpha)
data.pref.pref_spde
data.pref.pref_spde <- list(yy = yy.pref, mu = mu, ii = ii, jj = jj, alpha = alpha)
formula <- yy ~ alpha + mu + f(ii, model = spde) +
f(jj, copy = "ii", fixed = FALSE, param = c(0, 0.1)) -1
# Fit model
pref.model <-
inla(formula, family = c("gaussian", "poisson"),
control.family = list(list(initial = log(1/0.1), fixed = FALSE), list()),
control.inla = list(strategy = "gaussian", int.strategy = "eb"),
control.predictor = list(compute = TRUE),
data = data.pref.pref_spde, verbose = TRUE)
SKDat <- krige.control(obj.model = standardMLE, type.krige = "SK")
nonPredPref <- krige.conv(sampData, loc = predGrid, krige = SKDat, output=list(signal=T))
########################################################################
# Preferential predictions through INLA ################################
########################################################################
# Preferential parameters taken from INLA results
prefParam <- c(pref.model$summary.fixed[2,"mean"],
inla.emarginal(function(x) x / sqrt(8*nu),
pref.model$marginals.hyperpar[[2]]),
inla.emarginal(function(x) x^2, pref.model$marginals.hyperpar[[3]]),
inla.emarginal(function(x) 1/x, pref.model$marginals.hyperpar[[1]]),
pref.model$summary.hyperpar[4,"mean"])
# match indicies from INLA grid to grid used to generate data
matchedIndic <- row.match(predGrid,gridFull)
# get true field on INLA grid
rawDatSmall <- rawDat[matchedIndic]
# INLA predictions and prediction variances
predPrefINLA <-  list(predict=pref.model$summary.fitted.values[1:nrow(predGrid), "mean"],
variance=pref.model$summary.fitted.values[1:nrow(predGrid), "sd"]^2)
# Compare true field with preferential and non-preferential predictions
range1=c(min(c(rawDatSmall,predPrefINLA$predict,nonPredPref$predict)), max(c(rawDatSmall,predPrefINLA$variance, nonPredPref$predict)))
# TRUE
image.plot(Sseq,Sseq,matrix(rawDatSmall, nrow=length(Sseq), ncol=length(Sseq)),
xlab="Longitude", ylab="Latitude", main="True", zlim=range1, col=rev(heat.colors(20)))
points(sampData$coords, pch=19, cex=.5)
range2=c(min(c(predPrefINLA$variance, nonPredPref$krige.var)), max(c(predPrefINLA$variance, nonPredPref$krige.var)))
par(mfrow=c(2,2))
# Preferential predictions and variances
image.plot(Sseq,Sseq,matrix(predPrefINLA$predict, nrow=length(Sseq), ncol=length(Sseq)),
xlab="Longitude", ylab="Latitude", main="Pref Prediction", zlim=range1, col=rev(heat.colors(20)))
points(sampData$coords, pch=19, cex=.5)
image.plot(Sseq,Sseq,matrix(predPrefINLA$variance, nrow=length(Sseq), ncol=length(Sseq)),
xlab="Longitude", ylab="Latitude", main="Pref Variance", zlim=range2, col=rev(heat.colors(20)))
points(sampData$coords, pch=19, cex=.5)
# Non-Preferential prediction and variances
image.plot(Sseq,Sseq,matrix(nonPredPref$predict, nrow=length(Sseq), ncol=length(Sseq)),
xlab="Longitude", ylab="Latitude", main="NonPref Prediction", zlim=range1, col=rev(heat.colors(20)))
points(sampData$coords, pch=19, cex=.5)
image.plot(Sseq,Sseq,matrix(nonPredPref$krige.var, nrow=length(Sseq), ncol=length(Sseq)),
xlab="Longitude", ylab="Latitude", main="NonPref Variance", zlim=range2, col=rev(heat.colors(20)))
points(sampData$coords, pch=19, cex=.5)
rmultinom(n=20, size=3, prob=c(0.4,0.3,0.3))
library(INLA)
inla.list.models()
library(INLA)
inla.models()
inla.list.models()
inla.list.models()[likelihood]
inla.list.models[Section [likelihood]
inla.list.models()[Section likelihood]
# Define the linear dynamic model parameters
a <- 0.9  # State transition coefficient
b <- 1.0  # State transition bias
sigma_process <- 0.1  # Process noise standard deviation
sigma_observation <- 0.5  # Observation noise standard deviation
# Generate synthetic data
set.seed(123)
n_steps <- 100
true_state <- numeric(n_steps)
obs_noise <- rnorm(n_steps, mean = 0, sd = sigma_observation)
for (t in 2:n_steps) {
true_state[t] <- a * true_state[t - 1] + b + rnorm(1, mean = 0, sd = sigma_process)
}
# Initialize particle filter parameters
n_particles <- 1000
particles <- data.frame(
state = rnorm(n_particles, mean = 0, sd = 1),  # Initial state guesses
weight = rep(1 / n_particles, n_particles)  # Initial weights
)
# Sequential Monte Carlo (Particle Filter) algorithm
filtered_states <- numeric(n_steps)
for (t in 1:n_steps) {
# Predict the next state for each particle
particles$state <- a * particles$state + b + rnorm(n_particles, mean = 0, sd = sigma_process)
# Update particle weights based on the likelihood of the observation
particles$weight <- dnorm(obs_noise[t], mean = particles$state, sd = sigma_observation)
# Normalize particle weights
particles$weight <- particles$weight / sum(particles$weight)
# Resample particles based on their weights
resampled_indices <- sample(1:n_particles, size = n_particles, replace = TRUE, prob = particles$weight)
particles <- particles[resampled_indices, ]
# Estimate the state as the weighted mean of particles
filtered_states[t] <- sum(particles$state * particles$weight)
}
# Plot the true state and the filtered estimate
plot(1:n_steps, true_state, type = "l", col = "blue", lwd = 2, xlab = "Time", ylab = "State")
lines(1:n_steps, filtered_states, col = "red", lwd = 2)
legend("topright", legend = c("True State", "Filtered Estimate"), col = c("blue", "red"), lwd = 2)
# Load the particles package
library(particles)
# Define the linear system
A <- matrix(c(2, -1, 1, 3), nrow = 2, byrow = TRUE)
b <- c(1, 4)
# Define the likelihood function
likelihood <- function(x, data) {
mu <- A %*% x
sigma <- diag(0.1, nrow = length(data))
dmvnorm(data, mean = mu, sigma = sigma, log = TRUE)
}
# Define the prior distribution (assume a simple uniform prior for this example)
prior <- function(x) {
dunif(x, min = -10, max = 10, log = TRUE)
}
install.packages("particles")
# Load the particles package
library(particles)
# Define the linear system
A <- matrix(c(2, -1, 1, 3), nrow = 2, byrow = TRUE)
b <- c(1, 4)
# Define the likelihood function
likelihood <- function(x, data) {
mu <- A %*% x
sigma <- diag(0.1, nrow = length(data))
dmvnorm(data, mean = mu, sigma = sigma, log = TRUE)
}
# Define the prior distribution (assume a simple uniform prior for this example)
prior <- function(x) {
dunif(x, min = -10, max = 10, log = TRUE)
}
# Create the state space model
ssm <- statespace_model(
dyn_fn = function(x, param) x,  # No dynamic model (static problem)
obs_fn = observation_function(likelihood, data = b),
param_names = paste0("x", 1:length(b)),
prior = prior
)
# Load the particles package
library(particles)
# Define the linear system
A <- matrix(c(2, -1, 1, 3), nrow = 2, byrow = TRUE)
b <- c(1, 4)
# Define the likelihood function
likelihood <- function(x, data) {
mu <- A %*% x
sigma <- diag(0.1, nrow = length(data))
dmvnorm(data, mean = mu, sigma = sigma, log = TRUE)
}
# Define the prior distribution (assume a simple uniform prior for this example)
prior <- function(x) {
dunif(x, min = -10, max = 10, log = TRUE)
}
# Create the state space model
ssm <- statespace_model(
dyn_fn = function(x, param) x,  # No dynamic model (static problem)
obs_fn = observation_function(likelihood, data = b),
param_names = paste0("x", 1:length(b)),
prior = prior
)
install.packages("spup")
install.packages("spup")
rm(list = ls())
#setwd("C:/Users/Usuario/Desktop/mypackage")
setwd("C:/Users/Usuario/Desktop/htps")
library(devtools)
library(Rcpp)
library(RcppArmadillo)
library(pkgKitten)
compileAttributes(verbose=TRUE) # Find and register Rcpp functions
pkgbuild::compile_dll()
rm(list = ls())
#setwd("C:/Users/Usuario/Desktop/mypackage")
setwd("C:/Users/Usuario/Desktop/htps")
library(devtools)
library(Rcpp)
library(RcppArmadillo)
library(pkgKitten)
#RcppArmadillo.package.skeleton( "mypackage" )
compileAttributes(verbose=TRUE) # Find and register Rcpp functions
pkgbuild::compile_dll()
rm(list = ls())
#setwd("C:/Users/Usuario/Desktop/mypackage")
setwd("C:/Users/Usuario/Desktop/htps")
library(devtools)
library(Rcpp)
library(RcppArmadillo)
library(pkgKitten)
#RcppArmadillo.package.skeleton( "mypackage" )
compileAttributes(verbose=TRUE) # Find and register Rcpp functions
pkgbuild::compile_dll()
rm(list = ls())
#setwd("C:/Users/Usuario/Desktop/mypackage")
setwd("C:/Users/Usuario/Desktop/htps")
library(devtools)
library(Rcpp)
library(RcppArmadillo)
library(pkgKitten)
#RcppArmadillo.package.skeleton( "mypackage" )
compileAttributes(verbose=TRUE) # Find and register Rcpp functions
pkgbuild::compile_dll()
rm(list = ls())
#setwd("C:/Users/Usuario/Desktop/mypackage")
setwd("C:/Users/Usuario/Desktop/htps")
library(devtools)
library(Rcpp)
library(RcppArmadillo)
library(pkgKitten)
#RcppArmadillo.package.skeleton( "mypackage" )
compileAttributes(verbose=TRUE) # Find and register Rcpp functions
pkgbuild::compile_dll()
